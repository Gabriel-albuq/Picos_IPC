{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c2a01c",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8237ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Rectangle\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from datetime import datetime\n",
    "#import onnx\n",
    "#import onnxruntime as ort\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(base_dir)\n",
    "\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a377e0",
   "metadata": {},
   "source": [
    "# 2. Funcoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190cb824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Definir o dispositivo (GPU ou CPU)\n",
    "\n",
    "class CustomTransform: # Transformação das imagens\n",
    "    def __call__(self, img, target):\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            return img.to(device), target  # Verifica se a imagem é tensor, caso seja já envia para o dispositivo\n",
    "\n",
    "        img = transforms.ToTensor()(img)  # Caso não seja Tensor, transforma em tensor\n",
    "        return img.to(device), target  # Envia a imagem para o dispositivo\n",
    "    \n",
    "class CustomDataset(CocoDetection): # Configuração do dataset personalizado\n",
    "    def __init__(self, root, annotation, transforms=None):\n",
    "        super().__init__(root, annotation)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = super().__getitem__(idx)\n",
    "\n",
    "        if self.transforms:\n",
    "            img, target = self.transforms(img, target)  # Aplica a transformação na imagem e no target\n",
    "\n",
    "        return img, target\n",
    "\n",
    "def load_settings():\n",
    "    \"\"\"Função para ler as configurações de um arquivo .txt e atribuir os valores diretamente às variáveis.\"\"\"\n",
    "    # Valores padrão\n",
    "    defaults = {\n",
    "        'perc_top': 0.4,\n",
    "        'perc_bottom': 0.8,\n",
    "        'min_score': 0.5,\n",
    "        'limit_center': 8,\n",
    "        'save_dir': 'data\\\\outputs\\\\capturas',\n",
    "        'square_size': 640,\n",
    "        'grid_x': 0,\n",
    "        'grid_y': 0,\n",
    "        'crop_image': 1  # 1 = Sim\n",
    "    }\n",
    "\n",
    "    return (\n",
    "        defaults['perc_top'],\n",
    "        defaults['perc_bottom'],\n",
    "        defaults['min_score'],\n",
    "        defaults['limit_center'],\n",
    "        defaults['save_dir'],\n",
    "        defaults['square_size'],\n",
    "        defaults['grid_x'],\n",
    "        defaults['grid_y'],\n",
    "        defaults['crop_image'],\n",
    "    )\n",
    "\n",
    "def select_image(images_dir, image_choice):\n",
    "    base_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "    # Diretório onde estão as imagens e as anotações\n",
    "    annotations_path = fr'{images_dir}/_annotations.coco.json'  \n",
    "\n",
    "    # Carregar anotações COCO\n",
    "    with open(os.path.join(base_dir, annotations_path)) as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    # Criar um dicionário para mapear IDs de imagens para anotações\n",
    "    annotations_dict = {}\n",
    "    for annotation in coco_data['annotations']:\n",
    "        image_id = annotation['image_id']\n",
    "        if image_id not in annotations_dict:\n",
    "            annotations_dict[image_id] = []\n",
    "        annotations_dict[image_id].append(annotation)\n",
    "    images_dict = {image['id']: image['file_name'] for image in coco_data['images']}\n",
    "\n",
    "    if 0 <= image_choice < len(coco_data['images']):\n",
    "        image_info = coco_data['images'][image_choice]\n",
    "        image_file = image_info['file_name']\n",
    "        image_path = os.path.join(base_dir, images_dir, image_file)\n",
    "        image_id = image_info['id']\n",
    "        \n",
    "        # Obter anotações para a imagem selecionada\n",
    "        annotations = annotations_dict.get(image_id, [])\n",
    "        \n",
    "        return image_path, annotations, image_file\n",
    "    \n",
    "def visualize_coco_all_annotations(image_path, annotations, image_name):\n",
    "    # Carregar a imagem original\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Converter para RGB para exibição com matplotlib\n",
    "    \n",
    "    # Criar uma cópia para desenhar anotações\n",
    "    annotated_image = image_rgb.copy()\n",
    "    \n",
    "    # Exibir informações da imagem\n",
    "    height, width, channels = image.shape\n",
    "    print(f\"Exibindo imagem: {image_name}\")\n",
    "    print(f\"Dimensões da imagem: {width}x{height} (largura x altura, {channels} canais)\")\n",
    "\n",
    "    # Desenhar as bounding boxes na imagem anotada\n",
    "    for annotation in annotations:\n",
    "        x, y, w, h = annotation['bbox']\n",
    "        cv2.rectangle(annotated_image, (int(x), int(y)), (int(x + w), int(y + h)), color=(255, 0, 0), thickness=2)\n",
    "        print(f\"Coordenadas da bounding box: x={x}, y={y}, width={w}, height={h}\")\n",
    "    \n",
    "    # Criar uma figura com 2 subplots: imagem original e anotada\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # Subplot 1: imagem original\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(\"Imagem Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Subplot 2: imagem com anotações\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(annotated_image)\n",
    "    plt.title(f\"Imagem com anotações: {len(annotations)} detecções\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def create_model(weights, num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=weights)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_pretrained_model(device, model, pretrained_model_path):\n",
    "    if pretrained_model_path and os.path.exists(pretrained_model_path):\n",
    "        model.load_state_dict(torch.load(pretrained_model_path, map_location=device))\n",
    "        print(f\"Modelo carregado de: {pretrained_model_path}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Treinando modelo do zero...\")\n",
    "\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def load_model_eval(device, model, pretrained_model_path):  # Colocar o modelo em modo de avaliação\n",
    "    model.load_state_dict(torch.load(pretrained_model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "    \n",
    "    return model\n",
    "\n",
    "def dataset_config(images_dir, annotations_path, data_loader_batch_size):\n",
    "    dataset = CustomDataset(\n",
    "        root=os.path.join(base_dir, images_dir),\n",
    "        annotation=os.path.join(base_dir, annotations_path),\n",
    "        transforms=CustomTransform()  # Passa a transformação customizada\n",
    "    )\n",
    "\n",
    "    # Configuração do DataLoader\n",
    "    data_loader = DataLoader(dataset, batch_size=data_loader_batch_size, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "    return dataset, data_loader\n",
    "\n",
    "def load_image_tensor(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Carrega a imagem e converte para RGB\n",
    "    transform = transforms.ToTensor()  # Define a transformação para ToTensor\n",
    "    image_tensor = transform(image).unsqueeze(0)  # Converte a imagem para tensor e adiciona uma dimensão de batch\n",
    "    \n",
    "    return image_tensor\n",
    "\n",
    "def rules_detection(frame, detections_sorted, perc_top, perc_bottom, min_score, limit_center):\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    # Define as posições das linhas\n",
    "    line_limit_top = int(height * perc_top)    # Só conta quando a mediana entrar nesse range\n",
    "    line_limit_bottom = int(height * perc_bottom)   # Só conta quando a mediana entrar nesse range\n",
    "    dif_limit = line_limit_bottom - line_limit_top\n",
    "\n",
    "    # Linha de limite superior\n",
    "    cv2.line(\n",
    "        frame, \n",
    "        (0, line_limit_top), \n",
    "        (frame.shape[1], line_limit_top), \n",
    "        (0, 255, 0),  # Verde\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    # Linha de limite inferior\n",
    "    cv2.line(\n",
    "        frame, \n",
    "        (0, line_limit_bottom), \n",
    "        (frame.shape[1], line_limit_bottom), \n",
    "        (0, 255, 0),  # Verde\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    line_top_detect = None  # É calculada a mediana das detecções, e só são contados biscoitos que estão naquela mediana + - um valor de range\n",
    "    line_bottom_detect = None   # É calculada a mediana das detecções, e só são contados biscoitos que estão naquela mediana + - um valor de range\n",
    "\n",
    "    # Lista para armazenar centros de detecções\n",
    "    centers = []\n",
    "    all_centers_y = ([])  # Lista para armazenar as coordenadas y dos centros detectados\n",
    "\n",
    "    total_detections = 0  # Contador total de detecções\n",
    "\n",
    "    ### CALCULO DA MEDIANA\n",
    "    for idx, detection in enumerate(detections_sorted):\n",
    "        score = detection[1]   # Pontuação de confiança\n",
    "        x_min, y_min, x_max, y_max = detection[0]  # Coordenadas da caixa - y cresce de cima para baixo\n",
    "\n",
    "        # Verificar se a pontuação é maior que o limite e se está entre as linhas de contagem\n",
    "        if (score > min_score and y_max > line_limit_top and y_min < line_limit_bottom):\n",
    "            center_y = (y_min + y_max) // 2   # Calcular o centro da caixa de detecção\n",
    "            all_centers_y.append(center_y)  # Adiciona y à lista de centros\n",
    "\n",
    "    if all_centers_y:\n",
    "        median_y = int(np.median(all_centers_y))  # Obtém a mediana\n",
    "        line_bottom_detect = int(median_y + int(dif_limit / 2))\n",
    "        line_top_detect = int(median_y - int(dif_limit / 2))\n",
    "        \n",
    "        cv2.line(\n",
    "            frame, \n",
    "            (640, median_y), \n",
    "            (640 + 640, median_y), \n",
    "            (255, 0, 0), \n",
    "            2,\n",
    "        )  # Desenhar a linha horizontal na moda\n",
    "\n",
    "    ### MARCACAO\n",
    "    if ( all_centers_y and line_limit_bottom > median_y > line_limit_top):   # Se tiver pelo menos uma marcação dentro dos limites e a mediana for dentro dos limites\n",
    "        for idx, detection in enumerate(detections_sorted):\n",
    "            score = detection[1]   # Pontuação de confiança\n",
    "            x_min, y_min, x_max, y_max = detection[0]  # Coordenadas da caixa - y cresce de cima para baixo\n",
    "\n",
    "            center_x = int((x_min + x_max) // 2)   # Calcular o centro da caixa de detecção\n",
    "            center_y = int((y_min + y_max) // 2)\n",
    "\n",
    "            test_score = score > min_score   # Verifica score da deteccao\n",
    "            test_center = not any(np.linalg.norm(np.array([center_x, center_y]) - np.array(center))< limit_center for center in centers)   # Verifica se está próximo de algum centro\n",
    "            test_center_x = not any(abs(center_x - center[0]) < limit_center for center in centers)   # Verifica se está próximo de algum x dos centros\n",
    "            test_median = (y_max > line_top_detect and y_min < line_bottom_detect)   # Verifica se está na mediana +- range\n",
    "\n",
    "            if test_score and test_center and test_median:\n",
    "                total_detections += 1\n",
    "                # print(f\"Deteccao {str(total_detections)} ({idx + 1}): {str(score)} - OK (Score: {test_score} / Center: {test_center} / Center X: {test_center_x} / Median: {test_median})\")\n",
    "\n",
    "                centers.append((center_x, center_y))  # Adiciona o centro à lista\n",
    "\n",
    "                cv2.circle(\n",
    "                    frame, \n",
    "                    (center_x, center_y), \n",
    "                    limit_center, # Caso nao queira que seja igual o limit_center, tirar o comentado abaixo e colocar aqui um numero fixo\n",
    "                    (0, 0, 255), \n",
    "                    -1,\n",
    "                )   # Desenhar uma bolinha (círculo) no centro\n",
    "\n",
    "                cv2.circle(\n",
    "                    frame, \n",
    "                    (center_x, center_y), \n",
    "                    limit_center, \n",
    "                    (255, 0, 0), \n",
    "                    1,\n",
    "                )  # Círculo vermelho de limite\n",
    "\n",
    "                # cv2.putText(\n",
    "                #     frame,\n",
    "                #     str(total_detections),\n",
    "                #     (center_x - 6, center_y + 3),\n",
    "                #     cv2.FONT_HERSHEY_SIMPLEX,0.35,(255, 255, 255),\n",
    "                #     1,\n",
    "                # )   # Colocar o número da marcação dentro da bolinha\n",
    "\n",
    "    cv2.line(\n",
    "        frame, \n",
    "        (640, line_top_detect), \n",
    "        (640 + 640, line_top_detect), \n",
    "        (255, 0, 0), \n",
    "        2,\n",
    "\n",
    "    )\n",
    "    cv2.line(\n",
    "        frame,\n",
    "        (640,\n",
    "         line_bottom_detect),\n",
    "         (640 + 640, line_bottom_detect),\n",
    "         (255, 0, 0),\n",
    "         2,\n",
    "    )\n",
    "\n",
    "    return frame, total_detections\n",
    "\n",
    "def no_rules_detection(frame, detections_sorted, perc_top, perc_bottom, min_score, limit_center):\n",
    "    total_detections = 0  # Contador total de detecções\n",
    "\n",
    "    for idx, detection in enumerate(detections_sorted):\n",
    "        score = detection[1]\n",
    "        x_min, y_min, x_max, y_max = detection[0]\n",
    "\n",
    "        center_x = int((x_min + x_max) // 2)\n",
    "        center_y = int((y_min + y_max) // 2)\n",
    "\n",
    "        total_detections += 1\n",
    "\n",
    "        # Marca o centro com um círculo vermelho\n",
    "        cv2.circle(\n",
    "            frame,\n",
    "            (center_x, center_y),\n",
    "            7,\n",
    "            (0, 0, 255),\n",
    "            -1,\n",
    "        )\n",
    "\n",
    "        # Círculo azul indicando o raio que antes era o limit_center\n",
    "        cv2.circle(\n",
    "            frame,\n",
    "            (center_x, center_y),\n",
    "            limit_center,\n",
    "            (255, 0, 0),\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        # Número da detecção\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            str(total_detections),\n",
    "            (center_x - 6, center_y + 3),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.35,\n",
    "            (255, 255, 255),\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    # Área superior de fundo do texto\n",
    "    cv2.rectangle(\n",
    "        frame,\n",
    "        (0, 0),\n",
    "        (frame.shape[1], 40),\n",
    "        (80, 43, 30),\n",
    "        -1,\n",
    "    )\n",
    "\n",
    "    # Texto de total\n",
    "    text = f'Total de Biscoitos: {total_detections}'\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        text,\n",
    "        (10, 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1,\n",
    "        (255, 255, 255),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    return frame, total_detections\n",
    "\n",
    "def visualize_predictions_image(print_images, device, model, image_tensor, coco_annotations=None, threshold=0.5, limit_center = 6, perc_top = 0.35, perc_bottom = 0.6):\n",
    "    # Tratamento inicial das imagens\n",
    "    image_np = image_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    image_detected = (image_np * 255).astype(np.uint8).copy()  # OpenCV usa 0-255\n",
    "    image_annotated = image_np.copy()\n",
    "\n",
    "    frame_bgr = cv2.cvtColor(image_detected, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Regras nas anotacoes\n",
    "    height, width = frame_bgr.shape[:2]\n",
    "    line_limit_top = int(height * perc_top)    # Só conta quando a mediana entrar nesse range\n",
    "    line_limit_bottom = int(height * perc_bottom)   # Só conta quando a mediana entrar nesse range\n",
    "\n",
    "    coco_annotations_rules = []\n",
    "    if coco_annotations:\n",
    "        for ann in coco_annotations:\n",
    "            x, y, w, h = ann['bbox']\n",
    "            y_min = y\n",
    "            y_max = y + h\n",
    "\n",
    "            # Filtrar somente as anotações dentro da faixa de interesse\n",
    "            if y_max > line_limit_top and y_min < line_limit_bottom:\n",
    "                coco_annotations_rules.append(ann)\n",
    "\n",
    "    # Regras na deteccao\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        predictions = model(image_tensor)\n",
    "\n",
    "    prediction = predictions[0]\n",
    "\n",
    "    boxes_pred = prediction['boxes'].cpu().detach().numpy()\n",
    "    scores = prediction['scores'].cpu().detach().numpy()\n",
    "\n",
    "    # Preparar detecções válidas no formato necessário\n",
    "    detections_sorted = [\n",
    "        (box, score) for box, score in zip(boxes_pred, scores) if score > threshold\n",
    "    ]\n",
    "\n",
    "    # Aplicar regras na imagem de detecção (OpenCV)\n",
    "    frame_bgr, total_detections = rules_detection(\n",
    "        frame=frame_bgr,\n",
    "        detections_sorted=detections_sorted,\n",
    "        perc_top=perc_top,\n",
    "        perc_bottom=perc_bottom,\n",
    "        min_score=threshold,\n",
    "        limit_center=limit_center,\n",
    "    )\n",
    "\n",
    "    print(f\"Anotacoes: {len(coco_annotations_rules)} / Deteccoes: {total_detections}\")\n",
    "    # Criar subplots\n",
    "    if print_images == True:\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "        # Imprimir Imagem Original\n",
    "        ax[0].imshow(image_np)\n",
    "        ax[0].axis('off')\n",
    "        ax[0].set_title('Imagem Original', fontsize=16)\n",
    "\n",
    "        # Imprimir Imagem com Anotações\n",
    "        ax[1].imshow(image_annotated)\n",
    "        \n",
    "        # Linha de limite superior\n",
    "        ax[1].axhline(y=line_limit_top, color='green', linewidth=2)\n",
    "\n",
    "        # Linha de limite inferior\n",
    "        ax[1].axhline(y=line_limit_bottom, color='green', linewidth=2)\n",
    "\n",
    "        ax[1].set_title(f'Imagem com Anotações: {len(coco_annotations_rules)}', fontsize=16)\n",
    "\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        if coco_annotations_rules:\n",
    "            for ann in coco_annotations_rules:\n",
    "                x, y, w, h = ann['bbox']\n",
    "                y_min = y\n",
    "                y_max = y + h\n",
    "\n",
    "                # Filtrar somente as anotações dentro da faixa de interesse\n",
    "                if y_max > line_limit_top and y_min < line_limit_bottom:\n",
    "                    rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='blue', facecolor='none')\n",
    "                    ax[1].add_patch(rect)\n",
    "\n",
    "        # Imprimir Imagem com Detecções\n",
    "        image_detected = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "        ax[2].imshow(image_detected)\n",
    "        ax[2].axis('off')\n",
    "        ax[2].set_title(f'Imagem com Detecções Regradas: {total_detections}', fontsize=16)\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    result = len(coco_annotations_rules) == total_detections\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f2201",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### Modelo ######################################\n",
    "# Iniciar\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Definir o dispositivo (GPU ou CPU)\n",
    "\n",
    "# Inputs\n",
    "save_dir = os.path.join(base_dir, 'data', 'inputs', 'ia_models', 'FRCNN Resnet50')\n",
    "models_path = os.path.join(base_dir, 'data', 'inputs', 'ia_models', 'FRCNN Resnet50')\n",
    "pretrained_model_path = os.path.join(models_path, 'best_faster_rcnn_model_20250520_zoom.pth')  # Altere para o caminho do modelo salvo (ex: 'caminho/para/modelo.pth') ou mantenha None para treinar do zero\n",
    "weights='FasterRCNN_ResNet50_FPN_Weights.COCO_V1'\n",
    "num_classes = 2  # Inclua o número de classes (background + classes)\n",
    "num_epochs = 10000\n",
    "data_loader_batch_size = 1\n",
    "\n",
    "model = create_model(weights, num_classes)\n",
    "model = load_pretrained_model(device, model, pretrained_model_path)\n",
    "model = load_model_eval(device, model, pretrained_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd6fe70",
   "metadata": {},
   "source": [
    "# 3. Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdc2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = r'data/inputs/train_images/COCO_2025.05_group/valid'  \n",
    "annotations_path = r'data/inputs/train_images/COCO_2025.05_group/valid/_annotations.coco.json'  \n",
    "image_choice = 20  # Escolher a imagem (ajuste conforme necessário)\n",
    "\n",
    "image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "print(image_path)\n",
    "\n",
    "print(f\"Modelo no modo de avaliação no dispositivo: {next(model.parameters()).device}\") # Verificar se o modelo está no dispositivo correto (GPU ou CPU)\n",
    "\n",
    "image_tensor = load_image_tensor(image_path)\n",
    "result = visualize_predictions_image(False, device, model, image_tensor, annotations, threshold=0.5, perc_top=0.1, perc_bottom=0.5)\n",
    "print(result)\n",
    "######################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c958fd6b",
   "metadata": {},
   "source": [
    "# 4 Check Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da02f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_geral(threshold, limit_center, print_images = False):\n",
    "    images_dir = r'data/inputs/train_images/COCO_2025.05_group/valid'  \n",
    "    annotations_path = r'data/inputs/train_images/COCO_2025.05_group/valid/_annotations.coco.json'  \n",
    "\n",
    "    total_images = 0\n",
    "    total_true = 0\n",
    "\n",
    "    ############################# 000 #############################\n",
    "    image_choice = 0  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.1, perc_bottom=0.5)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 001 #############################\n",
    "    image_choice = 1  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.4, perc_bottom=0.7)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 003 #############################\n",
    "    image_choice = 3  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.5)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 004 #############################\n",
    "    image_choice = 4  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.5, perc_bottom=0.9)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 005 #############################\n",
    "    image_choice = 5  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.5, perc_bottom=0.9)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 006 #############################\n",
    "    image_choice = 6  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.45, perc_bottom=0.9)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 007 #############################\n",
    "    image_choice = 7  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.45, perc_bottom=0.9)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 008 #############################\n",
    "    image_choice = 8  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.45, perc_bottom=0.9)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 009 #############################\n",
    "    image_choice = 9  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.5)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 010 #############################\n",
    "    image_choice = 10  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.5, perc_bottom=0.8)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 011 #############################\n",
    "    image_choice = 11  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.6)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 012 #############################\n",
    "    image_choice = 12  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.6)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 013 #############################\n",
    "    image_choice = 13  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.5, perc_bottom=0.9)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 014 #############################\n",
    "    image_choice = 14  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.6)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 015 #############################\n",
    "    image_choice = 15  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.6)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 016 #############################\n",
    "    image_choice = 16  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.15, perc_bottom=0.5)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 017 #############################\n",
    "    image_choice = 17  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.5, perc_bottom=0.85)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 018 #############################\n",
    "    image_choice = 18  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.1, perc_bottom=0.5)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 019 #############################\n",
    "    image_choice = 19  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.3, perc_bottom=0.55)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 020 #############################\n",
    "    image_choice = 20  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.1, perc_bottom=0.4)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 021 #############################\n",
    "    image_choice = 21  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.35, perc_bottom=0.6)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 022 #############################\n",
    "    image_choice = 22  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.55)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 023 #############################\n",
    "    image_choice = 23  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.55)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 024 #############################\n",
    "    image_choice = 24  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.55)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 025 #############################\n",
    "    image_choice = 25  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0, perc_bottom=0.3)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 026 #############################\n",
    "    image_choice = 26  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.4, perc_bottom=0.75)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 027 #############################\n",
    "    image_choice = 27  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.4, perc_bottom=0.75)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 028 #############################\n",
    "    image_choice = 28  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.1, perc_bottom=0.45)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 029 #############################\n",
    "    image_choice = 29  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.45, perc_bottom=0.8)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 030 #############################\n",
    "    image_choice = 30  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.45, perc_bottom=0.8)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 031 #############################\n",
    "    image_choice = 31  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.6, perc_bottom=0.9)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 032 #############################\n",
    "    image_choice = 32  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.6, perc_bottom=0.95)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 033 #############################\n",
    "    image_choice = 33  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.4, perc_bottom=0.7)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 034 #############################\n",
    "    image_choice = 34  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.35, perc_bottom=0.65)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 035 #############################\n",
    "    image_choice = 35  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.4, perc_bottom=0.75)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 036 #############################\n",
    "    image_choice = 36  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.5, perc_bottom=0.8)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 037 #############################\n",
    "    image_choice = 37  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.5)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 038 #############################\n",
    "    image_choice = 38  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.5)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 039 #############################\n",
    "    image_choice = 39  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.3, perc_bottom=0.6)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 040 #############################\n",
    "    image_choice = 40  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.4, perc_bottom=0.7)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 041 #############################\n",
    "    image_choice = 41  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.35, perc_bottom=0.8)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 042 #############################\n",
    "    image_choice = 42  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.25, perc_bottom=0.6)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 043 #############################\n",
    "    image_choice = 43  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.4, perc_bottom=0.80)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 044 #############################\n",
    "    image_choice = 44  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.2, perc_bottom=0.5)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 045 #############################\n",
    "    image_choice = 45  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.05, perc_bottom=0.4)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 046 #############################\n",
    "    image_choice = 46  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.05, perc_bottom=0.4)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 047 #############################\n",
    "    image_choice = 47  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.4, perc_bottom=0.7)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 048 #############################\n",
    "    image_choice = 48  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.4, perc_bottom=0.7)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 049 #############################\n",
    "    image_choice = 49  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.3, perc_bottom=0.6)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 050 #############################\n",
    "    image_choice = 50  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.25, perc_bottom=0.6)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 051 #############################\n",
    "    image_choice = 51  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.1, perc_bottom=0.4)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 052 #############################\n",
    "    image_choice = 52  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.1, perc_bottom=0.4)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 053 #############################\n",
    "    image_choice = 53  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.25, perc_bottom=0.6)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 054 #############################\n",
    "    image_choice = 54  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.6, perc_bottom=0.9)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "    ############################# 054 #############################\n",
    "    image_choice = 54  # Escolher a imagem (ajuste conforme necessário)\n",
    "    image_path, annotations, image_file = select_image(images_dir, image_choice)\n",
    "    print(image_path)\n",
    "    image_tensor = load_image_tensor(image_path)\n",
    "    result = visualize_predictions_image(print_images, device, model, image_tensor, annotations, threshold=threshold, limit_center=limit_center, perc_top=0.6, perc_bottom=0.9)\n",
    "    total_images += 1\n",
    "    if result == True:\n",
    "        total_true += 1\n",
    "\n",
    "\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "    print(f' Resultado Final: {total_true/total_images:.2f}%')\n",
    "\n",
    "    return total_true/total_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "limit_center = 6\n",
    "result = check_geral(threshold=threshold, limit_center=limit_center, print_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e3d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "limit_center_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 19]\n",
    "\n",
    "print_images = False\n",
    "\n",
    "best_result = 0.0\n",
    "for threshold in threshold_list:\n",
    "    for limit_center in limit_center_list:\n",
    "        result = check_geral(threshold=threshold, limit_center=limit_center)\n",
    "\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_threhold = threshold\n",
    "            best_limit_center = limit_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a695a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_result)\n",
    "print(best_threhold)\n",
    "print(best_limit_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c345b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c84f4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
